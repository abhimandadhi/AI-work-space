{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir(\"C:/Users/Mohan/Desktop/Others/All Workshops/FDP at Andaman/Data Sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN by creating an object of sequential class\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a convolution layer by using the \"Conv2D\" function\n",
    "#It takes 4 arguments: 1. No. of filters, 2. Shape of each filter 3. Input shape and type of image(RGB or Black and White) of each image\n",
    "#Feed the classifier with 64X64 resolution.\n",
    "#\"3\" stands for RGB i.e. colour image\n",
    "# 4. Activation function. 'relu' to be used as activation function and stands for rectifier function\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by taking the classifier object and add the pooling layer.\n",
    "# Take a 2x2 matrix to have minimum pixel loss and get a precise region where the feature are located.\n",
    "#Perform Pooling operation on the resultant feature maps after convolution operation is done on an image\n",
    "#Reduce the size of images as much as possible using pooling i.e try to reduce the total\n",
    "\n",
    "#Step2. Pooling th data\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by taking the classifier object and add the pooling layer.\n",
    "# Take a 2x2 matrix to have minimum pixel loss and get a precise region where the feature are located.\n",
    "#Perform Pooling operation on the resultant feature maps after convolution operation is done on an image\n",
    "#Reduce the size of images as much as possible using pooling i.e try to reduce the total \n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert all the pooled images into a continuous vector through Flattening.\n",
    "#The 2-D array of pooled image pixels are to be converted into a one dimensional single vector.\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a fully connected layer to which connect the set of nodes obtained after flattening step.\n",
    "#Nodes after flattening step will act as input layer to the fully connected layers(hidden layer between input and output layers)\n",
    "# 'Dense' is the function to add a fully connected layer\n",
    "#'units' defines the number of nodes that should be present in the hidden layer(value of units will be between no. of input nodes\n",
    "  # and output nodes. Common practice us to use a power of 2.)\n",
    "#' relu' is the activation function and is a rectifier function\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "#Optimizer parameter is to choose the stochastic gradient descent algorithm.\n",
    "#Loss parameter is to choose the loss function.\n",
    "#The metrics parameter is to choose the performance metric.\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 445s 22s/step - loss: 0.6806 - accuracy: 0.6500 - val_loss: 0.6903 - val_accuracy: 0.5500\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 376s 19s/step - loss: 0.6286 - accuracy: 0.8125 - val_loss: 0.6393 - val_accuracy: 0.7000\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 247s 12s/step - loss: 0.5617 - accuracy: 0.8900 - val_loss: 0.6191 - val_accuracy: 0.7000\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 254s 13s/step - loss: 0.5063 - accuracy: 0.9025 - val_loss: 0.6843 - val_accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 251s 13s/step - loss: 0.4526 - accuracy: 0.9200 - val_loss: 0.6853 - val_accuracy: 0.6000\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 247s 12s/step - loss: 0.3812 - accuracy: 0.9500 - val_loss: 0.7164 - val_accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 234s 12s/step - loss: 0.3326 - accuracy: 0.9500 - val_loss: 0.7408 - val_accuracy: 0.6000\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 258s 13s/step - loss: 0.2910 - accuracy: 0.9500 - val_loss: 0.7413 - val_accuracy: 0.6000\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 238s 12s/step - loss: 0.2572 - accuracy: 0.9500 - val_loss: 0.7918 - val_accuracy: 0.6000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 239s 12s/step - loss: 0.2314 - accuracy: 0.9500 - val_loss: 0.9170 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x218a96a3888>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "#use keras.preprocessing library for doing the synthesising part as well as to prepare the training set as well as\n",
    "#the test test set of images that are present in a properly structured directories\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip  = True)\n",
    "#horhttp://localhost:8888/notebooks/Desktop/Data%20Sets/AI/Convolutional-Neural-Network-%20Image-Classification.ipynb#izontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#Importing the dataset\n",
    "training_set = train_datagen.flow_from_directory('trainingset',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('testset',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "\n",
    "#Fit the classifier\n",
    "classifier.fit_generator(training_set,\n",
    "steps_per_epoch = 20,\n",
    "epochs = 10,\n",
    "validation_data = test_set,\n",
    "validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "1.ImageDataGenerator generate batches of tensor image data with real-time data augmentation.The data will be looped over (in batches).\n",
    "2.rescale' is a rescaling factor. Defaults to None. If None or 0, no rescaling is applied,otherwise we multiply the data by the value provided (after applying all other transformations).\n",
    "3.shear_range is a Float value.i.e. Shear Intensity (Shear angle in counter-clockwise direction in degrees) 4.zoom_range is a Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range].\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indice\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
